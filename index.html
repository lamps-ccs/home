
<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="generator" content="HTML Tidy for HTML5 for Apple macOS version 5.6.0">

    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Large AI Systems and Models with Privacy and Safety Analysis Workshop (LAMPS)">
    <meta name="keywords"
        content="Deep Learning, Machine Learning, Security, Adversarial Examples, Attacks, Intrusion Detection, Program Analysis, Malware, Botnets, Vulnerability, Phishing, Forensics, Neural Networks, Recurrent Networks, Generative Adversarial Networks, AISec">
    <meta name="author" content="CCS-LAMPS Chairs">
    <title>CCS-LAMPS25</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ" crossorigin="anonymous">
    <link href="./css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=K2D:400,700" rel="stylesheet" type="text/css">
    <!-- Custom styles for this template -->
    <link href="./css/agency.css" rel="stylesheet">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-QDQDHN7F62"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-QDQDHN7F62');
    </script>
</head>

<body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top navbar-shrink" id="mainNav">
        <div class="container">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">CCS-LAMPS 2025</a>
            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
                data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
                aria-label="Toggle navigation">Menu</button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav text-uppercase ml-auto">
                    <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#page-top">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#keynote">Keynotes</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#programme">Programme</a>
                    </li> -->
                    <!-- <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#accepted">Accepted Papers</a>
                    </li> -->
                    <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#cfp">Call for Papers</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#award">Best Paper Award</a>
                    </li> -->
                    <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" href="#committee">Committee</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link js-scroll-trigger" target="_blank"
                            href="https://www.sigsac.org/ccs/CCS2025/">ACM CCS</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Header -->
    <header class="masthead">
        <div class="container">
            <div class="intro-text">
                <div class="intro-heading">
                    2
                    <sup>
                        <small>
                            <b>nd</b>
                        </small>
                    </sup>
                    ACM Workshop on
                    <br>
                    Large AI Systems and Models with Privacy and Security Analysis
                </div>
                <div class="intro-lead-in">
                    <b>October 13, 2025</b> — Taipei, Taiwan
                </div>
                <div class="intro-lead-in">
                    co-located with the 32nd ACM Conference on Computer and Communications Security
                </div>
                <!-- <div class="photo-credit">
                    Photo:
                    <a target="_blank"
                        href="https://content.r9cdn.net/rimg/dimg/9e/00/7edd696b-city-11592-16ed2e36ce3.jpg?crop=true&width=1020&height=498">Wikipedia</a>
                    (License:
                    <a href="https://creativecommons.org/licenses/by/2.0/">
                        CC BY 2.0
                    </a>
                    )
                </div> -->
            </div>
        </div>
    </header>
    <section id="keynote">
        <div class="container">
            <div class="row">
                <h2 class="section-heading text-uppercase">Keynotes</h2>
            </div>
            <div class="row">
                <div class="col-lg-3">
                    <center>
                        <img src="img/pin-yu.png" class="portait">
                    </center>
                </div>
                <div class="col-lg-9 text-justify">
                    <h3 class="section-subheading">
                        <b>Title: Computational Safety for Generative AI</b>
                    </h3>
                    <details>
                        <summary>
                            <b>Pin-Yu Chen, Principal Research Scientist, IBM Thomas J. Watson Research Center</b>
                        </summary>
                        <p>Dr. Pin-Yu Chen is a principal research scientist at IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA. He is also the chief scientist of RPI-IBM AI Research Collaboration and PI of ongoing MIT-IBM Watson AI Lab projects. Dr. Chen received his Ph.D. in electrical engineering and computer science from the University of Michigan, Ann Arbor, USA, in 2016. Dr. Chen’s recent research focuses on AI safety and robustness. His long-term research vision is to build trustworthy machine learning systems. He received the IJCAI Computers and Thought Award in 2023. He is a co-author of the book “Adversarial Robustness for Machine Learning”. At IBM Research, he received several research accomplishment awards, including IBM Master Inventor, IBM Corporate Technical Award, and IBM Pat Goldberg Memorial Best Paper. His research contributes to IBM open-source libraries including Adversarial Robustness Toolbox (ART 360) and AI Explainability 360 (AIX 360). He has published more than 50 papers related to trustworthy machine learning at major AI and machine learning conferences, given tutorials at NeurIPS’22, AAAI(’22,’23,’24), IJCAI’21, CVPR(’20,’21,’23), ECCV’20, ICASSP(’20,’22,’23,’24), KDD’19, and Big Data’18, and organized several workshops for adversarial machine learning. He has been an IEEE Fellow since 2025. He is currently on the editorial board of Transactions on Machine Learning Research and IEEE Transactions on Signal Processing. He is also an Area Chair or Senior Program Committee member for NeurIPS, ICLR, ICML, AAAI, IJCAI, and PAKDD, and a Distinguished Lecturer of ACM. He received the IEEE GLOBECOM 2010 GOLD Best Paper Award and UAI 2022 Best Paper Runner-Up Award. In 2025, he received the IEEE SPS Industry Young Professional Leadership Award.
                        </p>
                    </details>
                    <p>Large language models (LLMs) and Generative AI (GenAI) are at the forefront of frontier AI research and technology. With their rapidly increasing popularity and availability, challenges and concerns about their misuse and safety risks are becoming more prominent than ever. In this talk, we introduce a unified computational framework for evaluating and improving a wide range of safety challenges in generative AI. Specifically, we will show new tools and insights to explore and mitigate the safety and robustness risks associated with state-of-the-art LLMs and GenAI models, including (i) safety risks in fine-tuning LLMs, (ii) LLM red-teaming and jailbreak mitigation, (iii) prompt engineering for safety debugging, and (iv) robust detection of AI-generated content.</p>
                </div>
            </div>
        </div>
    </section>
    <!-- <section class="bg-light" id="programme">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Programme</h2>
                    <table cellpadding="5">
                        <p>The following times are on CET (UTC +1).</p>
                        <tr>
                            <td class="orga" width="120px">09:00&ndash;9:15</td>
                            <td class="orga">Opening and Welcome</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">9:15&ndash;10:00</td>
                            <td class="orga uline">Keynote 1</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">When decentralization, security, and privacy are not friends</em>
                                <br>
                                <b>Carmela Troncoso</b>
                                , Associate Professor @ EPFL
                            </td>
                        </tr>
                        <tr>
                            <td class="orga">10:00&ndash;10:20</td>
                            <td class="orga">Coffee break</td>
                        </tr>
                        <tr>
                            <td class="orga">10:20-11:00</td>
                            <td class="orga uline">Spotlights</td>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">When Side-Channel Attacks Break the Black-Box Property of Embedded
                                    Artificial Intelligence</em>
                                <br>
                                <b>Authors</b>
                                : Benoit Coqueret (Univ. Rennes, Inria), Mathieu Carbone (Thales ITSEF), Olivier
                                Sentieys (Univ. Rennes, Inria), Gabriel Zaid (Thales ITSEF)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Lookin' Out My Backdoor! Investigating Backdooring Attacks Against
                                    DL-driven Malware Detectors</em>
                                <br>
                                <b>Authors</b>
                                : Mario D'Onghia (Politecnico di Milano), Federico Di Cesare (Politecnico di Milano),
                                Luigi Gallo (Cyber Security Lab, Telecom Italia), Michele Carminati (Politecnico di
                                Milano), Mario Polino (Politecnico di Milano), Stefano Zanero (Politecnico di Milano)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Not what you've signed up for: Compromising Real-World LLM-Integrated
                                    Applications with Indirect Prompt Injection</em>
                                <br>
                                <b>Authors</b>
                                : Sahar Abdelnabi (CISPA Helmholtz Center for Information Security), Kai Greshake
                                (Saarland University, sequire technology GmbH), Shailesh Mishra (Saarland University),
                                Christoph Endres (sequire technology GmbH), Thorsten Holz (CISPA Helmholtz Center for
                                Information Security), Mario Fritz (CISPA Helmholtz Center for Information Security)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Canaries and Whistles: Resilient Drone Communication Networks with (or
                                    without) Deep Reinforcement Learning</em>
                                <br>
                                <b>Authors</b>
                                : Chris Hicks (The Alan Turing Institute), Vasilios Mavroudis (The Alan Turing
                                Institute), Myles Foley (Imperial College London), Thomas Davies (The Alan Turing
                                Institute), Kate Highnam (Imperial College London), Tim Watson (The Alan Turing
                                Institute)
                            </td>
                        </tr>
                        </tr>
                        <tr>
                            <td class="orga">11:00&ndash;12:00</td>
                            <td class="orga uline">Poster session 1</td>
                        </tr>
                        <tr>
                            <td class="orga">12:00&ndash;13:30</td>
                            <td class="orga">Lunch</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">13:30&ndash;14:15</td>
                            <td class="orga uline">
                                Keynote 2
                                <br>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Emerging challenges in securing frontier AI systems</em>
                                <br>
                                <b>Mikel Rodriguez</b>
                                , AI Red Teaming @ Google Deepmind
                            </td>
                        </tr>
                        <tr>
                            <td class="orga">14:15&ndash;14:45</td>
                            <td class="orga">Break</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">14:45&ndash;15:30</td>
                            <td class="orga uline">
                                Keynote 3
                                <br>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Trustworthy AI and A Cybersecurity Perspective on Large Language
                                    Models</em>
                                <br>
                                <b>Mario Fritz</b>
                                , Faculty @ CISPA Helmholtz Center for Information Security
                            </td>
                        </tr>
                        </tr>
                        <tr>
                            <td class="orga">15:30&ndash;16:30</td>
                            <td class="orga uline">Poster session 2</td>
                        </tr>
                        <tr>
                            <td class="orga">16:30&ndash;16:45</td>
                            <td class="orga">Closing remarks</td>
                        </tr>
                    </table>
                </div>
            </div>
        </div>
    </section> -->
    <!-- <section id="accepted">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Accepted Papers</h2>
                    <p>
                        You can find the accepted papers in the
                        <a href="https://dl.acm.org/doi/proceedings/10.1145/3605764">proceedings</a>
                        .
                    </p>
                    <strong>Privacy-Preserving Machine Learning (Poster session 1)</strong>
                    <table cellpadding="5">
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Differentially Private Logistic Regression with Sparse
                                    Solutions</em>
                                <br>
                                <b>Authors</b>
                                : Amol Khanna (Booz Allen Hamilton), Fred Lu (Booz Allen Hamilton; University of
                                Maryland, Baltimore County), Edward Raff (Booz Allen Hamilton; University of
                                Maryland, Baltimore County), Brian Testa (Air Force Research Laboratory)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Equivariant Differentially Private Deep Learning: Why DP-SGD Needs
                                    Sparser Models</em>
                                <br>
                                <b>Authors</b>
                                : Florian A. Hölzl (Artifical Intelligence in Medicine, Technical University of
                                Munich), Daniel Rueckert (Artifical Intelligence in Medicine, Technical University
                                of Munich), Georgios Kaissis (Artifical Intelligence in Medicine, Technical
                                University of Munich)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Probing the Transition to Dataset-Level Privacy in ML Models Using
                                    an Output-Specific and Data-Resolved Privacy Profile</em>
                                <br>
                                <b>Authors</b>
                                : Tyler LeBlond (Booz Allen Hamilton), Joseph Munoz (Booz Allen Hamilton), Fred Lu
                                (Booz Allen Hamilton), Maya Fuchs (Booz Allen Hamilton), Elliot Zaresky-Williams
                                (Booz Allen Hamilton), Edward Raff (Booz Allen Hamilton), Brian Testa (Air Force
                                Research Laboratory)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Information Leakage from Data Updates in Machine Learning
                                    Models</em>
                                <br>
                                <b>Authors</b>
                                : Tian Hui (The University of Melbourne), Farhad Farokhi (University of Melbourne),
                                Olga Ohrimenko (The University of Melbourne)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Membership Inference Attacks Against Semantic Segmentation
                                    Models</em>
                                <br>
                                <b>Authors</b>
                                : Tomas Chobola (Helmholtz AI), Dmitrii Usynin (Department of Computing, Imperial
                                College London; Artificial Intelligence in Medicine and Healthcare, TUM), Georgios
                                Kaissis (Artificial Intelligence in Medicine and Healthcare, TUM; Institute for
                                Machine Learning in Biomedical Imaging, Helmholtz Zentrum München; Department of
                                Computing, Imperial College London)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Utility-preserving Federated Learning</em>
                                <br>
                                <b>Authors</b>
                                : Reza Nasirigerdeh (Technical University of Munich), Daniel Rueckert (Technical
                                University of Munich), Georgios Kaissis (Technical University of Munich)
                            </td>
                        </tr>
                    </table>
                    <strong>Machine Learning for Cybersecurity (Poster session 1)</strong>
                    <table cellpadding="5">
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Certified Robustness of Static Deep Learning-based Malware
                                    Detectors against Patch and Append Attacks</em>
                                <br>
                                <b>Authors</b>
                                : Daniel Gibert (CeADAR, University College Dublin), Giulio Zizzo (IBM Research
                                Europe), Quan Le (CeADAR, University College Dublin)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">AVScan2Vec: Feature Learning on Antivirus Scan Data for
                                    Production-Scale Malware Corpora</em>
                                <br>
                                <b>Authors</b>
                                : Robert J. Joyce (Booz Allen Hamilton, University of Maryland Baltimore County),
                                Tirth Patel (University of Maryland Baltimore County), Charles Nicholas (University
                                of Maryland Baltimore County), Edward Raff (Booz Allen Hamilton, University of
                                Maryland Baltimore County)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Drift Forensics of Malware Classifiers</em>
                                <br>
                                <b>Authors</b>
                                : Theo Chow (King's College London), Zeliang Kan (King's College London), Lorenz
                                Linhardt (Technische Universität Berlin), Lorenzo Cavallaro (University College
                                London), Daniel Arp (Technische Universität Berlin), Fabio Pierazzi (King's College
                                London)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Lookin' Out My Backdoor! Investigating Backdooring Attacks Against
                                    DL-driven Malware Detectors</em>
                                <br>
                                <b>Authors</b>
                                : Mario D'Onghia (Politecnico di Milano), Federico Di Cesare (Politecnico di
                                Milano), Luigi Gallo (Cyber Security Lab, Telecom Italia), Michele Carminati
                                (Politecnico di Milano), Mario Polino (Politecnico di Milano), Stefano Zanero
                                (Politecnico di Milano)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Reward Shaping for Happier Autonomous Cyber Security Agents</em>
                                <br>
                                <b>Authors</b>
                                : Elizabeth Bates (The Alan Turing Institute), Vasilios Mavroudis (The Alan Turing
                                Institute), Chris Hicks (The Alan Turing Institute)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Raze to the Ground: Query-Efficient Adversarial HTML Attacks on
                                    Machine-Learning Phishing Webpage Detectors</em>
                                <br>
                                <b>Authors</b>
                                : Biagio Montaruli (SAP Security Research, EURECOM), Luca Demetrio (Università degli
                                Studi di Genova), Maura Pintor (University of Cagliari), Battista Biggio (University
                                of Cagliari), Luca Compagna (SAP Security Research), Davide Balzarotti (EURECOM)
                            </td>
                        </tr>
                    </table>
                    <strong>Machine Learning Security (Poster session 2)</strong>
                    <table cellpadding="5">
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Certifiers Make Neural Networks Vulnerable to Availability
                                    Attacks</em>
                                <br>
                                <b>Authors</b>
                                : Tobias Lorenz (CISPA Helmholtz Center for Information Security), Marta Kwiatkowska
                                (University of Oxford), Mario Fritz (CISPA Helmholtz Center for Information
                                Security)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Not what you've signed up for: Compromising Real-World
                                    LLM-Integrated Applications with Indirect Prompt Injection</em>
                                <br>
                                <b>Authors</b>
                                : Sahar Abdelnabi (CISPA Helmholtz Center for Information Security), Kai Greshake
                                (Saarland University, sequire technology GmbH), Shailesh Mishra (Saarland
                                University), Christoph Endres (sequire technology GmbH), Thorsten Holz (CISPA
                                Helmholtz Center for Information Security), Mario Fritz (CISPA Helmholtz Center for
                                Information Security)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Canaries and Whistles: Resilient Drone Communication Networks with
                                    (or without) Deep Reinforcement Learning</em>
                                <br>
                                <b>Authors</b>
                                : Chris Hicks (The Alan Turing Institute), Vasilios Mavroudis (The Alan Turing
                                Institute), Myles Foley (Imperial College London), Thomas Davies (The Alan Turing
                                Institute), Kate Highnam (Imperial College London), Tim Watson (The Alan Turing
                                Institute)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">The Adversarial Implications of Variable-Time Inference</em>
                                <br>
                                <b>Authors</b>
                                : Dudi Biton (Ben Gurion University of the Negev), Aditi Misra (University of
                                Toronto), Efrat Levy (Ben Gurion University of the Negev), Jaidip Kotak (Ben Gurion
                                University of the Negev), Ron Bitton (Ben Gurion University of the Negev), Roei
                                Schuster (Wild Moose), Nicolas Papernot (University of Toronto and Vector
                                Institute), Yuval Elovici (Ben Gurion University of the Negev), Ben Nassi (Cornell
                                Tech)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Dictionary Attack on IMU-based Gait Authentication</em>
                                <br>
                                <b>Authors</b>
                                : Rajesh Kumar (Bucknell University), Can Isik (Syracuse University), CHILUKURI
                                MOHAN (Syracuse University)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">When Side-Channel Attacks Break the Black-Box Property of Embedded
                                    Artificial Intelligence</em>
                                <br>
                                <b>Authors</b>
                                : Benoit Coqueret (Univ. Rennes, Inria), Mathieu Carbone (Thales ITSEF), Olivier
                                Sentieys (Univ. Rennes, Inria), Gabriel Zaid (Thales ITSEF)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Task-Agnostic Safety for Reinforcement Learning</em>
                                <br>
                                <b>Authors</b>
                                : Md Asifur Rahman (Wake Forest University), Sarra Alqahtani (Wake Forest
                                University)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Broken Promises: Measuring Confounding Effects in Learning-based
                                    Vulnerability Discovery</em>
                                <br>
                                <b>Authors</b>
                                : Erik Imgrund (SAP Security Research), Tom Ganz (SAP Security Research), Martin
                                Härterich (SAP Security Research), Niklas Risse (Max-Planck-Institute for Security
                                and Privacy), Lukas Pirch (Technische Universität Berlin), Konrad Rieck (Technische
                                Universität Berlin)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Measuring Equality in Machine Learning Security Defenses: A Case
                                    Study in Speech Recognition</em>
                                <br>
                                <b>Authors</b>
                                : Luke E. Richards (University of Maryland, Baltimore County), Edward Raff
                                (University of Maryland, Baltimore County; Booz Allen Hamilton), Cynthia Matuszek
                                (University of Maryland, Baltimore County)
                            </td>
                        </tr>
                    </table>
                </div>
            </div>
    </section> -->

    <!-- <section class="bg-light" id="program">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Program - Oct 14, 2024</h2>

                    <h3 class="section-heading">Full-day Workshop</h3>
                    <p>The following times are on local time zone.</p>

                    <table cellpadding="5">
                        <tr>
                            <td class="orga" width="120px">9:20&ndash;9:30</td>
                            <td class="orga">Opening Remarks</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">9:30&ndash;10:30</td>
                            <td class="orga uline">Keynote Speech 1: Ben Zhao （Professor, University of Chicago）</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">10:30&ndash;11:00</td>
                            <td class="orga">Morning Coffee Break</td>
                        </tr>

                        <tr>
                            <td class="orga" width="120px">11:00&ndash;11:30</td>
                            <td class="orga uline">	Session I: Cybersecurity Threat Intelligence</td>
                        </tr>

                        <tr>
                            <td></td>
                            <td>11:00: <em class="paper">ThreatKG: An AI-Powered System for Automated Online Threat Intelligence</em><br/>
                                <i>Peng Gao (Virginia Tech), Xiaoyuan Liu (University of California, Berkeley), Edward Choi (University of California, Berkeley), Sibo Ma (University of California, Berkeley), Xinyu Yang (Virginia Tech), and Dawn Song (University of California, Berkeley)</i>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>11:10: <em class="paper">Mitigating Unauthorized Speech Synthesis for Voice-Activated Systems</em><br/>
                                <i>Zhisheng Zhang (Beijing University of Posts and Telecommunications), Qianyi Yang (Beijing University of Posts and Telecommunications), Derui Wang (CSIRO's Data61), Pengyang Huang (Beijing University of Posts and Telecommunications), Yuxin Cao (National University of Singapore), Kai Ye (The University of Hong Kong), and Jie Hao (Beijing University of Posts and Telecommunications)</i>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>11:20: <em class="paper">How to Efficiently Manage Critical Infrastructure Vulnerabilities? Toward Large Code-graph Models</em><br/>
                                <i>Hongying Zhang (Shanghai Jiao Tong University), Gaolei Li (Shanghai Jiao Tong University), Shenghong Li (Shanghai Jiao Tong University), Hongfu Liu (Shanghai Jiao Tong University), Shuo Wang (Shanghai Jiao Tong University), and Jianhua Li (Shanghai Jiao Tong University)</i>
                            </td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">11:30&ndash;12:00</td>
                            <td class="orga uline">	Session II: Adversarial Attacks and Robustness</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>11:30: <em class="paper">Adversarial Attacks to Multi-Modal Models</em><br/>
                                <i>Zhihao Dou (Duke University), Xin Hu (The University of Tokyo), Haibo Yang (Rochester Institute of Technology), Zhuqing Liu (The Ohio State University), and Minghong Fang (Duke University)</i>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>11:40: <em class="paper">TrojFair: Trojan Fairness Attacks</em><br/>
                                <i>Jiaqi Xue (University of Central Florida), Mengxin Zheng (University of Central Florida), Yi Sheng (George Mason University), Lei Yang (George Mason University), Qian Lou (University of Central Florida), and Lei Jiang (Indiana University Bloomington)</i>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>11:50: <em class="paper">PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts</em><br/>
                                <i>Kaijie Zhu (Institute of Automation, Chinese Academy of Sciences), Jindong Wang (Microsoft Research), Jiaheng Zhou (Institute of Automation, Chinese Academy of Sciences), Zichen Wang (Institute of Automation, Chinese Academy of Sciences), Hao Chen (Carnegie Mellon University), Yidong Wang (Peking University), Linyi Yang (Westlake University), Wei Ye (Peking University), Yue Zhang (Westlake University), Neil Gong (Duke University), and Xing Xie (Microsoft)</i>
                            </td>
                        </tr>

                        
                        <tr>
                            <td class="orga" width="120px">12:00&ndash;14:00</td>
                            <td class="orga">Lunch</td>
                        </tr>

                        
                        <tr>
                            <td class="orga" width="120px">14:00&ndash;15:00</td>
                            <td class="orga uline">Keynote Speech 2: Chaowei Xiao （NVIDIA and University of Wisconsin, Madison）</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">15:00&ndash;15:30</td>
                            <td class="orga">Afternoon Coffee Break</td>
                        </tr>

                        <tr>
                            <td class="orga" width="120px">15:30&ndash;16:00</td>
                            <td class="orga uline">	Session III: Large Language Model Security</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>15:30: <em class="paper">Have You Merged My Model? On The Robustness of Merged Machine Learning Models</em><br/>
                                <i>Tianshuo Cong (Tsinghua University), Delong Ran (Tsinghua University), Zesen Liu (Xidian University), Xinlei He (The Hong Kong University of Science and Technology (Guangzhou)), Jinyuan Liu (Tsinghua University), Yichen Gong (Tsinghua University), Qi Li (Tsinghua University), Anyu Wang (Tsinghua University), and Xiaoyun Wang (Tsinghua University)</i>
                            </td>
                        </tr>

                        <tr>
                            <td></td>
                            <td>15:40: <em class="paper">"Prompter Says": A Linguistic Approach to Understanding and Detecting Jailbreak Attacks Against Large-Language Models</em><br/>
                                <i>Dylan Lee (University of California, Irvine), Shaoyuan Xie (University of California, Irvine), Shagoto Rahman (University of California, Irvine), Kenneth Pat (University of California, Irvine), David Lee (University of California, Irvine), and Qi Alfred Chen (University of California, Irvine)</i>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>15:50: <em class="paper">Towards Large Language Model (LLM) Forensics Using Feature Extraction</em><br/>
                                <i>Maxim Chernyshev (Deakin University), Zubair Baig (Deakin University), and Robin Ram Mohan Doss (Deakin University)</i>
                            </td>
                        </tr>
                        
                        
                    
                        <tr>
                            <td class="orga" width="120px">16:00&ndash;16:20</td>
                            <td class="orga uline">	Session IV: Secure Learning and Model Attribution</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>16:00: <em class="paper">CryptoTrain: Fast Secure Training on Encrypted Data</em><br/>
                                <i>Jiaqi Xue (University of Central Florida), Yancheng Zhang (University of Central Florida), Yanshan Wang (University of Pittsburgh), Xueqiang Wang (University of Central Florida), Hao Zheng (University of Central Florida), and Qian Lou (University of Central Florida)</i>
                            </td>
                        </tr>

                        <tr>
                            <td></td>
                            <td>16:10: <em class="paper">Detection and Attribution of Diffusion Model of Character Animation Based on Spatio-Temporal Attention</em><br/>
                                <i>Fazhong Liu (Shanghai Jiao Tong University), Yan Meng (Shanghai Jiao Tong University), Tian Dong (Shanghai Jiao Tong University), Guoxing Chen (Shanghai Jiao Tong University), and Haojin Zhu (Shanghai Jiao Tong University)</i>
                            </td>
                        </tr>

                        <tr>
                            <td class="orga" width="120px">16:20&ndash;16:30</td>
                            <td class="orga">Concluding Remarks</td>
                        </tr>
                    </table>

                </div>
            </div>
        </div>
    </section> -->

    <section id="cfp">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Call for Papers</h2>
                    <h3 class="section-subheading">Important Dates</h3>
                    <ul>
                        <li>
                            Paper submission deadline:
                            July 11, 2025, 11:59 PM (all deadlines are AoE, UTC-12)
                        </li>
                        <li>
                            Acceptance notification:
                            August 15, 2025
                        </li>
                        <li>Camera ready due:
                            August 22, 2025</li>
                        <li>Workshop day:
                            October 13, 2025</li>
                    </ul>
                    <h3 class="section-subheading">Overview</h3>
                    <p>
                        As Large AI Systems and Models (LAMs) become increasingly pivotal in a wide array of applications, their
                        potential impact on the privacy and cybersecurity of critical infrastructure becomes a pressing
                        concern. LAMPS is dedicated to addressing these unique challenges, fostering a dialogue on the
                        latest advancements and ethical considerations in enhancing the privacy and cybersecurity of
                        LAMs, particularly in the context of critical infrastructure protection.
                    </p>
                    <p>
                        LAMPS will bring together global experts to dissect the nuanced privacy and cybersecurity
                        challenges posed by LAMs, especially in critical infrastructure sectors. This workshop will
                        serve as a platform to unveil novel techniques, share best practices, and chart the course for
                        future research, with a special emphasis on the delicate balance between advancing AI
                        technologies and securing critical digital and physical systems.
                    </p>
                    <h3 class="section-subheading">Topics of Interest</h3>
                    <p>Topics of interest include (but are not limited to):</p>
                    <p>
                        <b>Secure Large AI Systems and Models for Critical Infrastructure</b>
                    </p>
                    <ul>
                        <li>AI-Enhanced Threat Intelligence and Detection</li>
                        <li>Automated Security Orchestration and Incident Response</li>
                        <li>Large AI Models in Vulnerability Assessment and Penetration Testing</li>
                        <li>AI-Driven Network Security Management</li>
                        <li>AI-Enabled Security Awareness and Education</li>
                        <li>Collaborative AI for Global Cyber Threat Intelligence Sharing</li>
                        <li>Regulatory Compliance and AI in Cybersecurity</li>
                    </ul>
                    <p>
                        <b>Large AI Systems and Models' Privacy and Security Vulnerabilities</b>
                    </p>
                    <ul>
                        <li>Advanced Threat Landscape</li>
                        <li>Holistic Security and Privacy Frameworks</li>
                        <li>Innovations in Privacy Preservation</li>
                        <li>Secure Computation in AI</li>
                    </ul>
                    <p>
                        <b>Data Anonymization and Synthetic Data</b>
                    </p>
                    <ul>
                        <li>Advancements in Data Protection</li>
                        <li>Cross-Border Data Flow and Cooperation</li>
                        <li>Intellectual Property Protection</li>
                        <li>Combatting Deepfakes</li>
                    </ul>
                    <p>
                        <b>Human-Centric Large AI Systems and Models</b>
                    </p>
                    <ul>
                        <li>User Vulnerability and Defense Mechanisms</li>
                        <li>Equity and Inclusivity in AI</li>
                        <li>Participative Large AI Governance</li>
                        <li>Enhancing Explainability and Trust</li>
                        <li>Designing for Security and Usability</li>
                        <li>Ethics and Decision-Making in AI</li>
                        <li>Frameworks for Responsible AI Governance</li>
                    </ul>
                    <h3 class="section-subheading">Submission Guidelines</h3>
                    <p>
                        Submitted papers must not substantially overlap with papers that have been published or simultaneously submitted to a journal or a conference with proceedings.
                    </p>
                    <ul>
                        <li>Short Papers: These papers should present concise and focused contributions, such as preliminary research findings, novel ideas with early evidence, or case studies relevant to the aforementioned topics of interest. Submissions must be up to 4 pages of body text in the ACM double-column format. Short papers must offer a clear and well-motivated contribution, even if the work is at an early stage, and should be of interest to the research community.</li>
                        <li>Research Papers: These papers should present new work, evidence, or ideas related to aforementioned topics of interest. Submission must be up to 8 pages of body text in the ACM double-column format, excluding well-marked references and appendices, and at most 10 pages. Research papers must be well-argued and worthy of publication and citation, on one of the topics listed above.</li>
                        <li>Systematization of knowledge (SoK) Papers: These papers should either consolidate and clarify ideas in a major research area within secure and trustworthy machine learning or provided compelling evidence to support or challenge long-held beliefs in such areas. Submission must be up to 8 pages of body text in the ACM double-column format, excluding well-marked references and appendices, and at most 10 pages. SoK papers must include "SoK:" at the beginning of their title.</li>
                        <li>Position Papers: These papers should cover broader issues and visions related to aforementioned topics of interest, including open challenges, technical perspectives, educational aspects, societal impact, or notable research results. Submissions must be very well-argued and consist of at most 4 pages of body text in the ACM double-column format, excluding well-marked references and appendices, and at most 5 pages in total. Position papers must include "Position:" at the beginning of their title.</li>
                    </ul>
                    <h3 class="section-subheading">Submission Site</h3>
                    <p>
                        Submission link:
                        <a href="https://ccs25-lamps.hotcrp.com">https://ccs25-lamps.hotcrp.com</a>
                    </p>
                    <p>
                        Only PDF files will be accepted. Submissions not meeting these guidelines risk rejection
                        without consideration of their merits. Authors of accepted papers must guarantee that one of the
                        authors will register and present the paper at the workshop. Proceedings of the workshop will be
                        available on a CD to the workshop attendees and will become part of the ACM Digital Library.
                    </p>
                    <p>
                        The archival papers will be included in the workshop proceedings. Due
                        to time constraints, accepted papers will be selected for presentation as either talk or poster
                        based on their review score and novelty. Nonetheless, all accepted papers should be considered
                        as having equal importance.
                    </p>
                    <p>
                        Authors are responsible for obtaining appropriate publication clearances. Attendance and
                        presentation by at least one author of each accepted paper at the workshop are mandatory for the
                        paper to be included in the proceedings.
                    </p>
                    <p>
                        For any questions, please contact one of the PC co-chairs Maggie Liu: 
                        <a href="mailto:xiaoning.liu@rmit.edu.au">xiaoning.liu@rmit.edu.au</a>.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- <section id="award">
        <div class="container">
            <div class="col-lg-12 text-justify">
                <h2 class="section-heading text-uppercase">Best Paper Award</h2>
                <p>
                    We will award the best paper, selected by the reviewers
                    among all the submitted papers.
                </p>
            </div>
        </div>
    </section> -->
    <section id="committee" class="bg-light">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-left">
                    <h2 class="section-heading text-uppercase">Committee</h2>
                    <h3 class="section-subheading">PC Chairs</h3>
                    <ul class="noindent">
                        <li>
                            <img src="./img/lam.jpg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://dr.ntu.edu.sg/cris/rp/rp00321" target="_blank">Lam Kwok Yan</a>
                            , Nanyang Technological University, Singapore
                        </li>
                        <li>
                            <img src="./img/derui.png" height="100em" width="80" style="margin: 10px;">
                            <a href="https://people.csiro.au/W/D/derek-wang" target="_blank">Derui Wang</a>
                            , CSIRO's Data61, Australia
                        </li>
                        <li>
                            <img src="./img/xiaoning.jpg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://www.rmit.edu.au/profiles/l/xiaoning-liu" target="_blank">Maggie Liu</a>
                            , RMIT University, Australia
                        </li>
                    </ul>
                    <h3 class="section-subheading">Web/Publication Chair</h3>
                    <ul class="noindent">
                        <li>
                            <img src="./img/ruoxi.jpg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://scholar.google.com.au/citations?user=Ei4jdwQAAAAJ" target="_blank">Ruoxi Sun</a>
                            , CSIRO's Data61, Australia
                        </li>
                    </ul>
                    <h3 class="section-subheading">Organizing Committee</h3>
                    <ul class="noindent">
                        <li>
                            <img src="./img/Bo.png" height="100em" width="80" style="margin: 10px;">
                            <a href="https://aisecure.github.io/" target="_blank">Bo Li</a>
                            , University of Chicago, USA
                        </li>
                        <li>
                            <img src="./img/wenyuan.png" height="100em" width="80" style="margin: 10px;">
                            <a href="https://sites.google.com/view/xuwenyuan/main" target="_blank">Wenyuan Xu</a>
                            , Zhejiang University, China
                        </li>
                        <li>
                            <img src="./img/jieshan.jpeg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://chenjshnn.github.io/" target="_blank">Jieshan Chen</a>
                            , CSIRO's Data61, Australia
                        </li>
                        <!-- <li>
                            <img src="./img/yang.png" height="100em" width="80" style="margin: 10px;">
                            <a href="https://yangzhangalmo.github.io/" target="_blank">Yang Zhang</a>
                            , CISPA, Germany
                        </li> -->
                        <li>
                            <img src="./img/Jason.jpg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://people.csiro.au/x/j/jason-xue" target="_blank">Jason Xue</a>
                            , CSIRO's Data61, Australia
                        </li>
                        <li>
                            <img src="./img/xyuan.jpg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://xyuancs.github.io/" target="_blank">Xingliang Yuan</a>
                            , The University of Melbourne, Australia
                        </li>
                        <li>
                            <img src="./img/guangdong.jpeg" height="100em" width="80" style="margin: 10px;">
                            <a href="https://baigd.github.io/" target="_blank">Guangdong Bai</a>
                            , The University of Queensland, Australia
                        </li>
                        <li>
                            <img src="./img/shuo.png" height="100em" width="80" style="margin: 10px;">
                            <a href="https://www.wang-shuo.com/" target="_blank">Shuo Wang</a>
                            , Shanghai Jiao Tong University, China
                        </li>
                    </ul>
                    <h3 class="section-subheading">Program Committee</h3>
                    <style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-bottom-width:1px;border-color:#ccc;border-style:solid;border-top-width:1px;
  border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;
  word-break:normal;}
.tg th{background-color:#f0f0f0;border-bottom-width:1px;border-color:#ccc;border-style:solid;border-top-width:1px;
  border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;
  padding:10px 5px;word-break:normal;}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-btxf{background-color:#f9f9f9;border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg" style="undefined;table-layout: fixed; width: 929px"><colgroup>
<col style="width: 150px">
<col style="width: 120px">
<col style="width: 400px">
<col style="width: 150px">
</colgroup>
<thead>
  <tr>
    <th class="tg-0pky">First</th>
    <th class="tg-0pky">Last</th>
    <th class="tg-0pky">Affiliation</th>
    <th class="tg-0pky">Countries and Regions</th>
  </tr></thead>
<tbody>
  <!-- <tr>
    <td class="tg-btxf">Chong</td>
    <td class="tg-btxf">Xiang</td>
    <td class="tg-btxf">Princeton University</td>
    <td class="tg-btxf">United States of America</td>
  </tr> -->
  <tr><td class="tg-btxf">Arpit</td><td class="tg-btxf">Garg</td><td class="tg-btxf">University of Adelaide</td><td class="tg-btxf">AU</td></tr>
<tr><td class="tg-btxf">Bang</td><td class="tg-btxf">Wu</td><td class="tg-btxf">RMIT</td><td class="tg-btxf">AU</td></tr>
<tr><td class="tg-btxf">Carsten</td><td class="tg-btxf">Maple</td><td class="tg-btxf">University of Warwick</td><td class="tg-btxf">GB</td></tr>
<tr><td class="tg-btxf">Coby</td><td class="tg-btxf">Wang</td><td class="tg-btxf">Visa Research</td><td class="tg-btxf">US</td></tr>
<!-- <tr><td class="tg-btxf">Derui</td><td class="tg-btxf">Wang</td><td class="tg-btxf">CSIRO's Data61</td><td class="tg-btxf">AU</td></tr> -->
<tr><td class="tg-btxf">Guanhong</td><td class="tg-btxf">Tao</td><td class="tg-btxf">University of Utah</td><td class="tg-btxf">US</td></tr>
<tr><td class="tg-btxf">Hyungjoon</td><td class="tg-btxf">Koo</td><td class="tg-btxf">Sungkyunkwan University</td><td class="tg-btxf">KR</td></tr>
<tr><td class="tg-btxf">Jiamou</td><td class="tg-btxf">Sun</td><td class="tg-btxf">CSIRO's Data61</td><td class="tg-btxf">AU</td></tr>
<tr><td class="tg-btxf">Jing</td><td class="tg-btxf">Xu</td><td class="tg-btxf">CISPA Helmholtz Center for Information Security</td><td class="tg-btxf">DE</td></tr>
<tr><td class="tg-btxf">Kristen</td><td class="tg-btxf">Moore</td><td class="tg-btxf">CSIRO's Data61</td><td class="tg-btxf">AU</td></tr>
<!-- <tr><td class="tg-btxf">Kwok-Yan</td><td class="tg-btxf">Lam</td><td class="tg-btxf">Nanyang Technological University, Singapore</td><td class="tg-btxf">SG</td></tr> -->
<tr><td class="tg-btxf">Linyi</td><td class="tg-btxf">Li</td><td class="tg-btxf">Simon Fraser University</td><td class="tg-btxf">CA</td></tr>
<tr><td class="tg-btxf">Mainack</td><td class="tg-btxf">Mondal</td><td class="tg-btxf">Indian Institute of Technology Kharagpur</td><td class="tg-btxf">IN</td></tr>
<tr><td class="tg-btxf">Marius</td><td class="tg-btxf">Fleischer</td><td class="tg-btxf">NVIDIA</td><td class="tg-btxf">US</td></tr>
<tr><td class="tg-btxf">Minghong</td><td class="tg-btxf">Fang</td><td class="tg-btxf">University of Louisville</td><td class="tg-btxf">US</td></tr>
<tr><td class="tg-btxf">Minxin</td><td class="tg-btxf">Du</td><td class="tg-btxf">The Hong Kong Polytechnic University</td><td class="tg-btxf">HK</td></tr>
<tr><td class="tg-btxf">Ryan</td><td class="tg-btxf">Sheatsley</td><td class="tg-btxf">University of Wisconsin-Madison</td><td class="tg-btxf">US</td></tr>
<tr><td class="tg-btxf">Shang-Tse</td><td class="tg-btxf">Chen</td><td class="tg-btxf">National Taiwan University</td><td class="tg-btxf">TW</td></tr>
<tr><td class="tg-btxf">Shuang</td><td class="tg-btxf">Hao</td><td class="tg-btxf">University of Texas at Dallas</td><td class="tg-btxf">US</td></tr>
<tr><td class="tg-btxf">SM</td><td class="tg-btxf">Yiu</td><td class="tg-btxf">The University of Hong Kong, Hong Kong</td><td class="tg-btxf">HK</td></tr>
<tr><td class="tg-btxf">Stjepan</td><td class="tg-btxf">Picek</td><td class="tg-btxf">Radboud University</td><td class="tg-btxf">NL</td></tr>
<tr><td class="tg-btxf">Tao</td><td class="tg-btxf">Ni</td><td class="tg-btxf">City University of Hong Kong</td><td class="tg-btxf">CN</td></tr>
<tr><td class="tg-btxf">Tian</td><td class="tg-btxf">Dong</td><td class="tg-btxf">Shanghai Jiao Tong University</td><td class="tg-btxf">CN</td></tr>
<tr><td class="tg-btxf">Tianshuo</td><td class="tg-btxf">Cong</td><td class="tg-btxf">Tsinghua University</td><td class="tg-btxf">CN</td></tr>
<tr><td class="tg-btxf">Veelasha</td><td class="tg-btxf">Moonsamy</td><td class="tg-btxf">Ruhr University Bochum</td><td class="tg-btxf">DE</td></tr>
<tr><td class="tg-btxf">Wanlun</td><td class="tg-btxf">Ma</td><td class="tg-btxf">Swinburne University of Technology</td><td class="tg-btxf">AU</td></tr>
<!-- <tr><td class="tg-btxf">Xiaoning</td><td class="tg-btxf">Liu</td><td class="tg-btxf">RMIT University, Australia</td><td class="tg-btxf">AU</td></tr> -->
<tr><td class="tg-btxf">Yongsen</td><td class="tg-btxf">Zheng</td><td class="tg-btxf">Nanyang Technological University</td><td class="tg-btxf">SG</td></tr>
<tr><td class="tg-btxf">Yuanyuan</td><td class="tg-btxf">Yuan</td><td class="tg-btxf">ETH Zurich</td><td class="tg-btxf">CH</td></tr>
<tr><td class="tg-btxf">Yufei</td><td class="tg-btxf">Chen</td><td class="tg-btxf">City University of Hong Kong</td><td class="tg-btxf">CN</td></tr>
<tr><td class="tg-btxf">Yuxin</td><td class="tg-btxf">Cao</td><td class="tg-btxf">National University of Singapore</td><td class="tg-btxf">SG</td></tr>
<tr><td class="tg-btxf">Zhiyuan</td><td class="tg-btxf">Zhang</td><td class="tg-btxf">Max Planck Institute for Security and Privacy</td><td class="tg-btxf">DE</td></tr>
<tr><td class="tg-btxf">Zitao</td><td class="tg-btxf">Chen</td><td class="tg-btxf">University of British Columbia</td><td class="tg-btxf">CA</td></tr>
<tr><td class="tg-btxf">Ziyao</td><td class="tg-btxf">Liu</td><td class="tg-btxf">Nanyang Technological University</td><td class="tg-btxf">SG</td></tr>
</tbody></table>
                    <!-- <p>We are currently looking for reviewers. Contact
                        <a href="mailto:TBD@xxx.xx">TBD@xxx.xx</a>
                        if you want to be involved.
                    </p> -->
                </div>
            </div>
        </div>
    </section>
    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-6">
                    <span class="copyright"><img src="./img/logo.jpg" alt="LAMPS" width="42" height="42">. Copyright © CCS-LAMPS 2025  <img src="./img/CCS-logo.png" alt="LAMPS" width="42" height="42"></span>
                    <br>
                </div>
                <!-- <div class="col-md-6">
                    Support kindly provided by the
                    <a href="https://www.unica.it/unica/en/homepage.page/" target="_blank">University of
                        Cagliari</a>
                    and by the
                    <a href="https://elsa-ai.eu/" target="_blank">
                        ELSA project
                    </a>
                    .
                    <br>
                    <img src="./temp_files/unica_800_black.png" height="50em" style="margin: 10px;">
                    <img src="./temp_files/elsa_logo_RGB_twocolor.jpg" height="50em" style="margin: 10px;">
                </div> -->
            </div>
        </div>
    </footer>
    <!-- <script src="./temp_files/jquery.slim.min.js.download"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
    <script src="./temp_files/bootstrap.bundle.min.js.download"
        integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe"
        crossorigin="anonymous"></script>
    <script src="./temp_files/agency.min.js.download"></script> -->


</body>

</html>